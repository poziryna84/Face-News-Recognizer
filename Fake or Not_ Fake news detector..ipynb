{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install autocorrect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport autocorrect\nfrom autocorrect import Speller\nimport string\nfrom nltk.tokenize import word_tokenize\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom nltk.stem import PorterStemmer\nimport re\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nimport spacy\nnlp = spacy.load('en_core_web_lg')\nimport unicodedata\nfrom itertools import chain \nfrom collections import Counter\nfrom textblob import TextBlob\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom IPython.display import FileLink","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/train-csv/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/test-scv/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/sample-sub/sample_submission.csv\")\nids = test['id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Functions.\n*Here some problem specific functions were created.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visual(num_var, target_var):\n    '''Function that takes a numerical variable and a categorical variable and returns the histogram of the distribution\n    of the numerical variable and two histograms of the distributions of the numerical variable filtered by the levels\n    of the categorical variable(in this case the 'target variable').\n    '''\n    \n    fig, ((ax0, ax1, ax2)) = plt.subplots(nrows=3, ncols=1)\n    n_bins = 20\n    colors = ['green']\n    ax0.hist(train[num_var], n_bins, density=True, histtype='bar', color=colors, \n             label=colors)\n    ax0.set_title('Total ' + ' '.join(num_var.split('_')).capitalize())\n\n    ax1.hist(train[num_var][train[target_var] == 0], n_bins, density=True, histtype='bar', stacked=True)\n    ax1.set_title(' '.join(num_var.split('_')).capitalize() +' in True comments')\n\n    ax2.hist(train[num_var][train[target_var] == 1], n_bins,  density=True, histtype='bar', stacked=True)\n    ax2.set_title(' '.join(num_var.split('_')).capitalize() +' False comments')\n\n    fig.tight_layout()\n    return plt.show()\n\ndef split_count(text):\n    '''The function that takes a string as an input and returns the number of emojis in the string as an output.\n    '''\n\n    emoji_list = []\n    data = regex.findall(r'\\X', text)\n    for word in data:\n        if any(char in emoji.UNICODE_EMOJI for char in word):\n            emoji_list.append(word)\n\n    return emoji_list\n\ndef replace_elem(text):\n    '''Function that separates two or more capitalized words written together and replaces problem specific elements\n    from the string:\n    'http...' - 'link'\n    '#', '@...', '&amp' - ''\n    \n    '''\n    text = ' '.join(['link' if i.startswith(('http')) else i for i in text.split()]).strip()\n    text = text.replace('#', ' ').replace('  ', ' ')\n    text = ' '.join([''.join([' ' + i if i.isupper() else i for i in e]).strip() if (len(e) >1 and e[0].isupper() and e[1].islower()) else e for e in text.split()])\n    text = text.replace('  ', ' ').strip()\n    text_clean = ' '.join(['' if i.startswith(('@', '&amp')) else i for i in text.split()]).strip()\n    \n    return text_clean\n\ndef strip_accents(text):\n    '''Function that eliminates accents from the string.\n    '''\n    \n    text = unicodedata.normalize('NFD', text)\\\n           .encode('ascii', 'ignore')\\\n           .decode(\"utf-8\")\n\n    return str(text)\n\ndef ent_replace(string):\n    '''Function that takes a string as an input and returns the string with entities replaced with the corresponding labels \n    from Spacy package.\n    '''\n    doc = nlp(string)\n    for ent in doc.ents:\n        string = string.replace(ent.text, ent.label_)\n    return string.lower()\n\ndef reduce_lengthening(text):\n    '''Function that eliminates more than two repeat letters from a word.\n    '''\n    pattern = re.compile(r\"(.)\\1{2,}\")\n    return pattern.sub(r\"\\1\\1\", text)\n\nspell = Speller(lang='en')\nresult = string.punctuation \ndef text_prepro(text):\n    '''Function that performs text preprocessing like spelling correction, 'cleaning' a string from stop words, digits, \n    accents, one letter word; entities replacement, stemming, etc.\n    '''\n    \n    text = reduce_lengthening(text)\n    stop_words = set(stopwords.words('english'))\n    new_stopwords = [\"i'm\", \"im\", \"there's\", \"that's\", \"wasnt\", 'as', 'thus']\n    new_stopwords_list = stop_words.union(new_stopwords)\n    text = replace_elem(text)\n    text = ent_replace(text)\n    text = ''.join([l if l not in result else ' ' for l in text])\n    text = text.lower()\n    text = spell(text)\n    word_tokens = word_tokenize(text) \n    filtered_sentence = [w for w in word_tokens if w not in new_stopwords_list and len(w) > 1]\n    #lemmatizer=WordNetLemmatizer()\n    porter = PorterStemmer()\n    stemmed_words = [porter.stem(word) for word in filtered_sentence if word.isalpha() and len(word) > 1]\n    stem_string = ' '.join(stemmed_words)\n    stemmed_string = strip_accents(stem_string)\n  \n    return stemmed_string\n\ndef spacy_counter(df, type_, text_column, target_column):\n    '''Functions that return a number of parts of speech or entetis from a string.\n    '''\n    def partofSpeachRec(text,tag):\n        doc = nlp(text)\n        pos = [token.pos_ for token in doc]\n        return pos.count(tag)\n    def entetiesRecog(text, tag):\n        doc = nlp(text)\n        labels = [ent.label_ for ent in doc.ents]\n        return labels.count(tag)\n    \n    if type_ == 'part_of_speech':\n        aux_list = ['ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON',\n                       'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X', 'SPACE']\n        function = partofSpeachRec\n    elif type_ == 'entety_label':\n        aux_list = ['PERSON', 'ORG', 'GPE', 'NORP', 'FAC', 'LOC', 'PRODUCT', 'EVENT', 'WORK_OF_ART','LAW', 'LANGUAGE', \n                    'DATE','TIME', 'PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL']\n        function = entetiesRecog\n    for i in aux_list:\n        df[i] = df[text_column].apply(lambda x: function(x, i))\n        real_mean = df[df[target_column] == 0][i].mean()\n        fake_mean = df[df[target_column] == 1][i].mean()\n        mean_diff = abs(real_mean - fake_mean)\n        \n        real_median = df[df[target_column] == 0][i].median()\n        fake_median = df[df[target_column] == 1][i].median()\n        \n        print(i)\n        print(\"Mean no. of %s in real and fake comments are %.2f and %.2f respectively with the difference of %.2f\"%(\n            i, real_mean, fake_mean, mean_diff))\n        print(\"Median no. of %s in real and fake comments are %.2f and %.2f respectively\"%(i, real_median, fake_median))\n\n    return df\n\ndef part_speech(string, tag):\n    '''Function that takes a string as an input and returns the number of specified part of the spech from it.\n    '''\n    doc = nlp(string)\n    token_list = [token.pos_ for token in doc]\n    return token_list.count(tag)\n\ndef ent(string, tag):\n    '''Function that takes a string as an input and returns the number of specified entety from it.\n    '''\n    doc = nlp(string)\n    ent_list = [ent.label_ for ent in doc.ents]\n    return ent_list.count(tag)\n\ndef train_and_predict(alpha, x_train, y_train, x_test, y_test):\n    '''Function that takes as an input the value of alpha and returns the corresponding f1_score of a Multinomial model.\n    '''\n    nb_classifier = MultinomialNB(alpha=alpha)\n    nb_classifier.fit(x_train, y_train)\n    pred = nb_classifier.predict(x_test)\n    score = f1_score(y_test, pred, average='micro')\n    return score\n\ndef text_vectorizer(text_column, ngram_range, x_set, add_col_list = None, add_keyword = None, min_df = 0.001, max_features = None,\n                    stand_sc = False):\n    '''Function that vectorizes a text column of the x_set with the option of adding additional columns of numeric values.\n    It also returns the columns of the features names.\n    '''\n    vectorizer = CountVectorizer(max_features = max_features, min_df = min_df, ngram_range = ngram_range)\n    X_bow = vectorizer.fit_transform(x_set[text_column])\n    X_bow_df = pd.DataFrame(X_bow.toarray()) \n    X_bow_df.columns = vectorizer.get_feature_names()\n    if add_col_list == None:\n        final_df = X_bow_df.copy()\n\n        if add_keyword == None:\n            final_df = final_df\n        else:\n            x_set[add_keyword].index = final_df.index\n            final_df = pd.concat([final_df, x_set[add_keyword].reset_index(drop = True)], axis = 1) \n            \n    else:\n        final_df = pd.concat([X_bow_df, x_set[add_col_list].reset_index(drop = True)], axis = 1)\n        if add_keyword == None:\n            final_df = final_df\n        else:\n            final_df = pd.concat([final_df, x_set[add_keyword].reset_index(drop = True)], axis = 1) \n\n    if stand_sc:\n        columns_aux = final_df.columns\n        scaler = MinMaxScaler()\n        scaler.fit(final_df)\n        final_df = scaler.transform(final_df)\n        final_df = pd.DataFrame(final_df)\n        final_df.columns = columns_aux\n    return final_df, final_df.columns\n\ndef col_replacer(columns, df):\n    '''Function that fills a data frame with columns in case the are missing in the data frame and puts them in the\n    right order according to the argument 'columns'. \n    '''\n    cols = columns\n    for i in columns:\n        if i not in df:\n            df[i] = 0\n    df = df[cols]   \n    return df\n\ndef predictor(model, df):\n    '''Function that takes as an input a test data frame and a model and creates a Kaggle submission format data frame \n    with the predictions.'''\n    \n    sub_array = model.predict(df)\n    \n    if sub_array.ndim == 2:\n        sub_array = [int(round(i[0])) for i in sub_array]\n        sub = pd.DataFrame()\n        sub['id'] = ids\n        sub['target'] = sub_array\n    else:\n        sub = pd.DataFrame()\n        sub['id'] = ids\n        sub['target'] = pd.Series(sub_array)\n    return sub\n\ndef descr_stats(df, num_col, contr_col):\n    '''Function that takes a data frame, one of its numerical columns and a categorical column and returns the descriptive statistics of the\n    total of the numerical variable and the numerical variable filtered by the levels of the categorical variable.'''\n    \n    a = df[num_col].describe().to_frame()\n    col_list = ['total']\n    num_lev = len(df[contr_col].value_counts().index)\n    for i in range(num_lev):\n           b = df[num_col][df[contr_col] == i].describe().to_frame()\n           col_list.append(contr_col + '_' + str(i))\n           a = pd.concat([a,b], axis = 1)\n           a.columns = col_list\n    return a\n        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engeneering part.\n"},{"metadata":{},"cell_type":"markdown","source":"*Let's create some structural features to describe the comment length, the number of digits, words, upper case letters, punctuations, spaces, ads, hashes, mean word length in a comment and visualize them.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data treatment:\n\ntrain['comment_length'] = [len(word_tokenize(item)) for item in train['text']]\n# Creates a list of lists, containing the tokens from text column.\ntokens = [word_tokenize(item) for item in train['text']]\n\ntrain['words_number'] = [len([word for word in item if word.isalpha()]) for item in tokens]\n\ntrain['punctuation_number'] = [len([word for word in item if not word.isalnum()]) for item in tokens]\n\ntrain['digits_number'] = [len([word for word in item if word.isdigit()]) for item in tokens]\n\ntrain['mean_word_length'] = train['text'].apply(lambda x: sum([len(i) for i in x if x.split()])/len(x.split()))\n\ntrain['spaces_number'] = train['text'].apply(lambda x: len(x.split()))\n\ntrain['upper_letters_number'] = train['text'].apply(lambda x: len([i for i in x if i.isupper()]))\n\ntrain['ats_number'] = train['text'].apply(lambda x: len([i for i in x if i == '@']))\n\ntrain['hash_number'] = train['text'].apply(lambda x: len([i for i in x if i == '#']))\n\n\n# Test data treatment:\n\ntest['comment_length'] = [len(word_tokenize(item)) for item in test['text']]\n# Creates a list of lists, containing the tokens from text column.\ntokens_ = [word_tokenize(item) for item in test['text']]\n\ntest['words_number'] = [len([word for word in item if word.isalpha()]) for item in tokens_]\n\ntest['punctuation_number'] = [len([word for word in item if not word.isalnum()]) for item in tokens_]\n\ntest['digits_number'] = [len([word for word in item if word.isdigit()]) for item in tokens_]\n\ntest['mean_word_length'] = test['text'].apply(lambda x: sum([len(i) for i in x if x.split()])/len(x.split()))\n\ntest['spaces_number'] = test['text'].apply(lambda x: len(x.split()))\n\ntest['upper_letters_number'] = test['text'].apply(lambda x: len([i for i in x if i.isupper()]))\n\ntest['ats_number'] = test['text'].apply(lambda x: len([i for i in x if i == '@']))\n\ntest['hash_number'] = test['text'].apply(lambda x: len([i for i in x if i == '#']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*I have noticed that some of the comments appear in the data set more than once and there might also be more than one \nlocation assigned to a given repeated comment. Let's create **'text_count'** and **'location_count'** variables.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"aux_df = pd.concat([train[['text', 'location']], test[['text', 'location']]], axis = 0)\naux_df['location'] = aux_df['location'].fillna('notknown')\n\naux_text_count = aux_df.groupby(\"text\").count().reset_index()\naux_text_count.columns = ['text', 'text_count']\n\naux_loc_count = aux_df.groupby(\"text\")[\"location\"].nunique().reset_index()\naux_loc_count.columns = ['text', 'location_count']\n\ntrain = pd.merge(train, aux_text_count,\n                how = 'left',\n                on = 'text')\ntest = pd.merge(test, aux_text_count,\n                how = 'left',\n                on = 'text')\n\ntrain = pd.merge(train, aux_loc_count,\n               how = 'left',\n               on = 'text')\ntest = pd.merge(test, aux_loc_count,\n               how = 'left',\n               on = 'text')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Text_count and Location count.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('text_count', 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('location_count', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Though the majority of the comments can only be encountered once, there is still some difference in the number of repeated comments and therefore location between true and false comments.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"descr_stats(train, 'text_count', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comment_length.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('comment_length', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Even though there are some really long comments among the true once, on average the false once are longer with the mean\nof 19.22 and standard deviation of 6 while the true comments have the mean of 18.6 and standard deviation 7.4.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"descr_stats(train, 'comment_length', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Words_number.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('words_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*On average the false comments contain more words than the true once with the mean\nof 14 and standard deviation of 4.9 while the true comments have the mean of 13.7 and standard deviation 6.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"descr_stats(train, 'words_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Punctuation_number.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('punctuation_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*While we can observe quite similar destributions when comes to the mean (4,56 and 4.77), first, second and third percentiles (2,4,6 and 3,4,6) in the cases of true and false comments respectively, true comments tend to have more extreme outliers.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"descr_stats(train, 'punctuation_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Digits_number.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('digits_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*The majority of the comments don't have digits in them, but in the case of the false comments the mean number is higher than in the case of true comments.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"descr_stats(train, 'digits_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Mean_word_length.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('mean_word_length', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*On average false comments tend to have more lengthy words than the true once with the mean of 7.4, first, second and third percentiles of 6.4, 7.3 and 8.2 respectively and the maximum of 20.16.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"descr_stats(train, 'mean_word_length', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Spaces_number.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('spaces_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distributions are quite similar, though the true comments seem to be more spread."},{"metadata":{"trusted":true},"cell_type":"code","source":"descr_stats(train, 'spaces_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Upper_letters_number.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('upper_letters_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"False comments seem to have more upper case letters on average (10.8 while true comments mean is 9.2), but the true comments are more spread\nwith the standard deviation of 10.94 which is higher than in the case of false commnets (9.6), which could be explained by the extreme outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"descr_stats(train, 'upper_letters_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ats_number.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('ats_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"True comments have more ats than the false once which can be explained by the fact that there are more discussions about true news than the false once."},{"metadata":{"trusted":true},"cell_type":"code","source":"descr_stats(train, 'ats_number', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Key_word.**"},{"metadata":{},"cell_type":"markdown","source":"*Let's take a look at a key word variable. Some of them are missing.\nSo we are going to create a dictionary with texts as keys and keywords as values and replace the missing values with the keywords of the same texts since we know that some texts are repeated.\nThen I will visualize the rusults.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_aux =  pd.concat([train[list(test.columns)],test], axis = 0)\ntrain_aux.drop_duplicates(subset='text', inplace= True)\nkw_dict = dict(zip(train_aux['text'][train_aux['keyword'].notna()],train_aux['keyword'][train_aux['keyword'].notna()]))\n\n# Train data treatment:\ntrain['keyword'] = train['keyword'].fillna(train['text'].map(kw_dict))\ntrain['keyword'].fillna('', inplace = True)\ntrain['keyword'] = train['keyword'].apply(lambda x: x.replace('%20', ''))\n\n# Test data treatment:\ntest['keyword'] = test['keyword'].fillna(train['text'].map(kw_dict))\ntest['keyword'].fillna('', inplace = True)\ntest['keyword'] = test['keyword'].apply(lambda x: x.replace('%20', ''))\n\nfull = pd.concat([train, test], axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Looking at the word clouds of true and false comments it´s clear that latter fall into more contentious topics like wreckage, derailment, etc., and since it's human labeled it could be useful to add the dummies of the keywords to as predictors as well.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud_comment_words = WordCloud(background_color=\"black\").generate(\n    ' '.join(list(train['keyword'][train['target'] == 0])))\nplt.imshow(cloud_comment_words, interpolation='bilinear') \nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cloud_comment_words = WordCloud(background_color=\"black\").generate(\n    ' '.join(list(train['keyword'][train['target'] == 1])))\nplt.imshow(cloud_comment_words, interpolation='bilinear') \nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Now if we take a look at the unique values of the keyword column of the full data set we can spot that some of the topics have the same root, like 'bloody' and 'blood', and therefore can be stemmed to reduce the number of the unique values of the keyword.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(full['keyword'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in full['keyword'].unique():\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"porter = PorterStemmer()\nfull['keyword'] = full['keyword'].apply(porter.stem)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(full['keyword'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Now let's dummify the keyword variable and create key_word_full data frame with the dummies of the keyword and the id of each comment, and then merge it with train and test data sets on 'id'.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"key_word_full = pd.get_dummies(full['keyword'],prefix = 'kw_', drop_first=True)\nkey_word_cols = [i for i in key_word_full.columns]\nkey_word_full['id'] = full['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train, key_word_full,\n                how = 'left',\n                on = 'id')\n\ntest = pd.merge(test, key_word_full,\n                how = 'left',\n                on = 'id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Let's do some text cleaning.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data treatment:\ntrain['text_modif'] = train['text'].apply(text_prepro)\n\n# Test data treatment:\ntest['text_modif'] = test['text'].apply(text_prepro)\n\n# Train data treatment:\ntrain['keyword'] = train['keyword'].apply(text_prepro)\n\n# Test data treatment:\ntest['keyword'] = test['keyword'].apply(text_prepro)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*To check the frequency of the words we are going to use the Collection from Counter.*"},{"metadata":{"_uuid":"d86eaf7e-4c69-4f34-9429-6f38a027d6d7","_cell_guid":"37705ee3-4783-4076-aa1f-de177ddc96ee","trusted":true},"cell_type":"code","source":"word_freq = Counter(chain.from_iterable(list(train['text_modif'].str.split())))\nmost_common = word_freq.most_common()\n\nword_freq_t1 = Counter(chain.from_iterable(list(train['text_modif'][train['target'] == 1].str.split())))\nmost_common_t1 = word_freq_t1.most_common()\n\nword_freq_t0 = Counter(chain.from_iterable(list(train['text_modif'][train['target'] == 0].str.split())))\nmost_common_t0 = word_freq_t0.most_common()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"470e8258-998e-4b56-a7d6-767dd68de470","_cell_guid":"7d0563cf-0193-4f9d-a6d7-8445ac544350","trusted":true},"cell_type":"code","source":"most_common_t1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f37fdb16-6a5e-4747-816c-04bee5ac2515","_cell_guid":"b897155e-ab7e-4586-87b3-4bfbfd7adae3","trusted":true},"cell_type":"code","source":"most_common_t0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47c56019-59da-40fd-a2ca-f92fe4041937","_cell_guid":"da95a692-69db-47ef-a65f-baf4754c0086","trusted":true},"cell_type":"markdown","source":"Next, we will compute the mean number of different parts of speech and name enteties used in fake and real comments and compare the values. If there is a remarkable difference, then there is a good chance that using the created feature in fake news detector will improve its performance."},{"metadata":{"_uuid":"7075814e-9071-4c4f-ad3c-435ff67a9a69","_cell_guid":"06358372-6053-4bcd-af40-8d0fff326bda","trusted":true},"cell_type":"code","source":"spacy_counter(train, 'part_of_speech', 'text', 'target')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a7d7a4e-9a83-4930-aab8-6f54e61c7948","_cell_guid":"02532eec-3769-4b66-a10d-d91d60ee7241","trusted":true},"cell_type":"markdown","source":"###### 1. It looks like the number of nouns (NOUN with the mean difference equal to 0.69), proper names (PROPN with the mean difference equal to 0.74), pronouns (PRON with the mean difference equal to 0.56) and adposition (ADP with the mean difference equal to 0.43) might do do some good to our model. Let's take a look at the number of parts of speech in the comments."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train data treatment:\ntrain['text'] = train['text'].apply(replace_elem)\ntrain['NOUN'] = train['text'].apply(lambda x: part_speech(x,'NOUN'))\ntrain['PROPN'] = train['text'].apply(lambda x: part_speech(x,'PROPN'))\ntrain['PRON'] = train['text'].apply(lambda x: part_speech(x,'PRON'))\ntrain['ADP'] = train['text'].apply(lambda x: part_speech(x,'ADP'))\n\n#Te data treatment:\ntest['text'] = test['text'].apply(replace_elem)\ntest['NOUN'] = test['text'].apply(lambda x: part_speech(x,'NOUN'))\ntest['PROPN'] = test['text'].apply(lambda x: part_speech(x,'PROPN'))\ntest['PRON'] = test['text'].apply(lambda x: part_speech(x,'PRON'))\ntest['ADP'] = test['text'].apply(lambda x: part_speech(x,'ADP'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Content Features: Content features are based on comments’ textual aspects and include polarity (the average positive or negative feelings expressed a comment), subjectivity (a score of whether a tweet is objective or subjective).*\n*But before we should get rid of the hash tags, ats, etc.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data treatment:\nstop_words = set(stopwords.words('english'))\nnew_stopwords = [\"i'm\", \"im\", \"there's\", \"that's\", \"wasnt\"]\nnew_stopwords_list = stop_words.union(new_stopwords)\n\ntrain['text'] = train['text'].apply(lambda x: ' '.join([i for i in x.lower().split() if (i.isalpha() and i not in new_stopwords_list)]))\ntrain['commenet_polar'] = train['text'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\ntrain['commenet_polar'] = np.where(((train['commenet_polar'] <= 1) & (train['commenet_polar'] >= 0.5)), 3,\n                                  np.where(((train['commenet_polar'] < 0.5) & (train['commenet_polar'] >= 0)), 2,\n                                           np.where(((train['commenet_polar'] < 0) & (train['commenet_polar'] >= -0.5)), 1, 0)))\n\ntrain['commenet_subject'] = train['text'].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)\n\n# Test data treatment:\ntest['text'] = test['text'].apply(lambda x: ' '.join([i for i in x.lower().split() if (i.isalpha() and i not in new_stopwords_list)]))\ntest['commenet_polar'] = test['text'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\ntest['commenet_polar'] =  np.where(((test['commenet_polar'] <= 1) & (test['commenet_polar'] >= 0.5)), 3,\n                                  np.where(((test['commenet_polar'] < 0.5) & (test['commenet_polar'] >= 0)), 2,\n                                           np.where(((test['commenet_polar'] < 0) & (test['commenet_polar'] >= -0.5)), 1, 0)))\n\ntest['commenet_subject'] = test['text'].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('commenet_polar', 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visual('commenet_subject', 'target')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature selection part.\n"},{"metadata":{},"cell_type":"markdown","source":"*Feature importance is an inbuilt class that comes with Tree Based Classifiers, we will be using Extra Tree Classifier for extracting the top n features for the dataset.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train[[ 'comment_length',\n       'words_number', 'punctuation_number', 'digits_number',\n       'mean_word_length', 'spaces_number', 'upper_letters_number',\n       'ats_number', 'hash_number', 'text_count',\n       'location_count','NOUN', 'PROPN', 'PRON', 'ADP',\n       'commenet_polar', 'commenet_subject']] \n\ny = train['target']\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(len(X)-1).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.to_csv(\"/kaggle/master.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling part.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"master = pd.read_csv(\"/kaggle/master.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ad_vars = ['comment_length', 'words_number', 'punctuation_number', 'digits_number', 'mean_word_length', 'spaces_number', \n           'upper_letters_number', 'ats_number', 'hash_number', 'text_count','location_count','NOUN', 'PROPN', 'PRON',\n           'ADP', 'commenet_polar', 'commenet_subject']\ntot_cols = ad_vars + key_word_cols + ['text_modif']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master = master[master.text_modif.notna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression."},{"metadata":{},"cell_type":"markdown","source":"*Bag of words.\nUsing (1,3) n-gramm baw vectores and new features.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"matr_lr, cols_lr = text_vectorizer(text_column = 'text_modif', ngram_range = (1,3), x_set = X, add_col_list = ad_vars,\n                                   add_keyword = key_word_cols, \n                                   min_df = 0.001, stand_sc = False)\n\nX_train, X_test, y_train, y_test = train_test_split(matr_lr, y, test_size=0.06, \n                                                    stratify = y, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Let's train a logistic regression model and calculate its F1 score.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_reg = LogisticRegression(C=0.5).fit(X_train, y_train)\n\nlog_preds = log_reg.predict(X_test)\n\nprint('F1 of logistic regression reg 0.01:', f1_score(y_test, log_preds, average='micro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Multinomial model."},{"metadata":{},"cell_type":"markdown","source":"*A unigram vectorizer on the text data and key words variables.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"matr_mn, cols_mn = text_vectorizer(text_column = 'text_modif', ngram_range = (1,1), x_set = X, add_col_list = None,\n                                   add_keyword = key_word_cols, \n                                   min_df = 0.001, stand_sc = False)\n\nX_train, X_test, y_train, y_test = train_test_split(matr_mn, y, test_size=0.06, \n                                                    stratify = y, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Here we are going to iterate over a range of values of alpha to optimize the model.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"alphas = np.arange(0, 1, 0.1)\n\nfor alpha in alphas:\n    print('Alpha: ', alpha)\n    print('Score: ', train_and_predict(alpha, X_train, y_train, X_test, y_test))\n    print()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = MultinomialNB(alpha = 0.2)\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\nprint('F1 of Multinomial NB: ', f1_score(y_test, predictions, average='micro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Let's explore the model and print out the most and the least important features.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_labels = clf.classes_\n\nfeature_names = cols_mn\n\n# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\nfeat_with_weights = sorted(zip(clf.coef_[0], feature_names))\n\n# Print the first class label and the top 20 feat_with_weights entries\nprint('Top 20 lowest values (less predictive features)')\nprint()\nprint(class_labels[0], feat_with_weights[:20])\nprint()\nprint('*******************************************************************************************************************************')\nprint()\n# Print the second class label and the bottom 20 feat_with_weights entries\nprint('top 20 highest values (highest predictive features)')\nprint()\nprint(class_labels[1], feat_with_weights[-20:])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Neural NetWork model."},{"metadata":{},"cell_type":"markdown","source":"*A data frame based on (1,2) gramm vectorized text using 1000 most frequent words, with key words and created varibales.\nThe data has been scaled as well.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"matr_nr, cols_nr = text_vectorizer(text_column = 'text_modif', ngram_range = (1,2), x_set = X, add_col_list = ad_vars,\n                                   add_keyword = key_word_cols,  max_features = None, min_df = 0.001, stand_sc = True)\n\nX_train, X_test, y_train, y_test = train_test_split(matr_nr, y, test_size=0.06, stratify = y, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Grid Search for the best parameters.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import Callback\nfrom sklearn.metrics import f1_score\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers import BatchNormalization\nfrom keras import optimizers\n\nns = X_train.shape[0] # number of samples in training data set.\nno = 1                # number of output neurons.\nni = X_train.shape[1] # number of input neurons\na = 6                 # an arbitrary scaling factor usually 2-10.\nnh = ns/(a**(ni + no))# number of hidden layer neurons\n\n# Creates a model given an activation learning rate and number of layers.\n\ndef create_model(drop_out, learning_rate, number_of_layers=1):\n    \n    model = Sequential()\n    model.add(Dense(ni, input_dim= ni, activation='relu'))\n    model.add(Dropout(drop_out))\n    if number_of_layers == 2:\n        model.add(Dense(nh, activation='relu'))\n        model.add(Dropout(drop_out))\n    model.add(Dense(1, activation='sigmoid'))\n    sgd = optimizers.Adamax(beta_1 = 0.4, beta_2 = 0.999)\n    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    \n    return model\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# Create a KerasClassifier\nmodel = KerasClassifier(build_fn = create_model)\n\n# Define the parameters to try out\nparams = {'batch_size': [60, 100, 200, 300,  500, 600], \n          'epochs': [50, 100, 300], \n          'number_of_layers': [1,2],\n          'drop_out': [ 0.2, 0.5],\n          'learning_rate': [0.1, 0.01, 0.001, 0.0001]}\n\n# Create a grid search cv object passing in the parameters to try\nsg = GridSearchCV(model, param_grid = params, cv = 3, scoring = 'f1_micro')\n\nsg.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#{'batch_size': 500, 'drop_out': 0.2, 'epochs': 200, 'learning_rate': 0.0001, 'number_of_layers': 1}\nprint(sg.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import Callback\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n\n# Create a Sequential model\nmodel = Sequential()\n\nmodel.add(Dense(ni, input_dim=ni, activation='relu'))\nmodel.add(Dropout(0.1))\n#model.add(Dense(no, activation='relu'))\n#model.add(Dropout(0.2))\n\nmodel.add(Dense(1, activation='sigmoid'))\nsgd = optimizers.Adamax(learning_rate=0.0001, beta_1 = 0.9, beta_2 = 0.999)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monitor_val_acc = EarlyStopping(monitor='val_accuracy', patience = 10)\n#Save the best model as best_banknote_model.hdf5\nmodelCheckpoint = ModelCheckpoint('Nnr_model.hdf5', save_best_only=True)\nhistory = model.fit(X_train, y_train, epochs=100, \n                    callbacks=[modelCheckpoint,monitor_val_acc],\n                    batch_size=200,\n                    validation_data = (X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Exploring the model.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('Model accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)\n\npredictions = [round(i[0]) for i in predictions]\nprint('F1 of Keras Net Work: ', f1_score(y_test, predictions, average='micro'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Applying Logistic Regression Model to the test data.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_lr, cols = text_vectorizer(text_column = 'text_modif', ngram_range = (1,3), x_set = test, add_col_list = ad_vars,\n                                   add_keyword = key_word_cols, \n                                   min_df = 0.001, stand_sc = False)\ntest_lr = col_replacer(columns = cols_lr, df = test_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = predictor(model = log_reg, df = test_lr)\nlr.to_csv('Log_reg.csv', index=False)\nFileLink(r'Log_reg.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Applying Multinomial Model to the test data.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_mn, cols1 = text_vectorizer(text_column = 'text_modif', ngram_range = (1,1), x_set = test, add_col_list = None,\n                                   add_keyword = key_word_cols,\n                                   max_features = None, min_df = 0.001, stand_sc = False)\n\ntest_mn = col_replacer(columns = cols_mn, df = test_mn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mn = predictor(model = clf, df = test_mn)\nmn.to_csv('mult_nom.csv', index=False)\nFileLink(r'mult_nom.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*Applying Neural Net Model to the test data.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_nr, cols2 = text_vectorizer(text_column = 'text_modif', ngram_range = (1,2), x_set = test, add_col_list = ad_vars,\n                                   add_keyword = key_word_cols,  max_features = None, min_df = 0.001, stand_sc = True)\n\ntest_nr = col_replacer(columns = cols_nr, df = test_nr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nnnr_model = load_model('Nnr_model.hdf5')\nnr = predictor(model = nnr_model, df = test_nr)\nnr.to_csv('neural_net.csv', index=False)\nFileLink(r'neural_net.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*As a conclusion of this project I must say there hasn't been much difference in the performance of the three models. On average they have 0.80\nF1 scroe on the test and 0.79 on the validation data. I started with the avrege score of 0.76 and managed to improve it by using text prepro -\ncessing tecniques such as spelling corection, entity labeling and chosing stemming over lematization.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}